### 14.1.2 Pythonの場合

import pandas as pd
my_data = pd.DataFrame(
    {'language': (  0, 20, 20, 25, 22, 17),
     'english':  (  0, 20, 40, 20, 24, 18),
     'math':     (100, 20,  5, 30, 17, 25),
     'science':  (  0, 20,  5, 25, 16, 23),
     'society':  (  0, 20, 30,  0, 21, 17)},
    index=['A', 'B', 'C', 'D', 'E', 'F'])

from pca import pca
my_model = pca(n_components=5)
my_result = my_model.fit_transform(my_data) # 主成分分析

my_result['PC'] # 主成分スコア
#>          PC1        PC2       PC3       PC4           PC5
#> A  74.907282   7.010808  0.361499  0.076343 -2.855324e-15
#> B -13.818842  -2.753459 -5.273039  0.841842  2.251702e-15
#> C -33.714034  18.417290  4.876294 -0.882042 -1.189989e-15
#> D  -1.730630 -17.876372  7.925076 -0.149317 -1.907888e-16
#> E -17.837474   1.064998 -1.652676  2.312541  3.195391e-15
#> F  -7.806303  -5.863266 -6.237154 -2.199367  3.088116e-16

my_result['explained_var'] # 累積寄与率
#> array([0.88848331, 0.97962854, 0.99858005, 1.        , 1.        ])

my_result['loadings'] # 主成分の係数ベクトル
#>      language   english      math   science   society
#> PC1 -0.207498 -0.304360  0.887261 -0.130198 -0.245204
#> PC2 -0.279463  0.325052  0.097643 -0.702667  0.559435
#> PC3  0.306117  0.615799  0.056345 -0.338446 -0.639815
#> PC4  0.764943 -0.471697 -0.007655 -0.418045  0.132455
#> PC5 -0.447214 -0.447214 -0.447214 -0.447214 -0.447214

my_model.biplot(legend=False) # バイプロット

import scipy.stats as sp
tmp = sp.stats.zscore(my_data, ddof=1) # 標準化

from pca import pca
my_model = pca(n_components=5)
my_result = my_model.fit_transform(tmp)

my_result['PC'] # 主成分スコア
#>           PC1       PC2       PC3       PC4           PC5
#> 1.0  3.673722  0.568850  0.058449  0.010636  3.966865e-16
#> 1.0 -0.652879 -0.246926 -0.434798  0.093045 -1.152979e-17
#> 1.0 -1.568294  1.742598  0.380571 -0.097734 -1.629400e-16
#> 1.0 -0.250504 -1.640039  0.675366 -0.031991  8.108395e-18
#> 1.0 -0.886186  0.110493 -0.092540  0.230379  1.559282e-16
#> 1.0 -0.315858 -0.534976 -0.587048 -0.204335 -2.517267e-16

import pandas as pd
my_data = pd.DataFrame(
    {'language': (  0, 20, 20, 25, 22, 17),
     'english':  (  0, 20, 40, 20, 24, 18),
     'math':     (100, 20,  5, 30, 17, 25),
     'science':  (  0, 20,  5, 25, 16, 23),
     'society':  (  0, 20, 30,  0, 21, 17)},
    index=['A', 'B', 'C', 'D', 'E', 'F'])

import numpy as np
tmp = my_data - my_data.mean()
Z = np.matrix(tmp)                        # 標準化しない場合
#Z = np.matrix(tmp / my_data.std())       # 標準化する場合
#Z = np.matrix(tmp / my_data.std(ddof=0)) # pca(normalize=True)と同じ

S = np.cov(Z, rowvar=0) # 分散共分散行列
w, v = np.linalg.eig(S) # 固有値と固有ベクトル
Z @ v                   # 主成分スコア
#> matrix([[ 7.49072823e+01,  7.01080827e+00, -3.61499394e-01,  7.63429938e-02, -4.44089210e-15],
#>         [-1.38188417e+01, -2.75345865e+00,  5.27303872e+00,  8.41842148e-01, -4.44089210e-16],
#>         [-3.37140337e+01,  1.84172903e+01, -4.87629358e+00, -8.82041934e-01, -3.55271368e-15],
#>         [-1.73063018e+00, -1.78763722e+01, -7.92507599e+00, -1.49317054e-01,  1.06581410e-14],
#>         [-1.78374741e+01,  1.06499788e+00,  1.65267588e+00,  2.31254121e+00,  2.66453526e-15],
#>         [-7.80630260e+00, -5.86326562e+00,  6.23715437e+00, -2.19936737e+00, -4.44089210e-15]])

w.cumsum() / w.sum() # 累積寄与率
#> array([0.88848331, 0.97962854, 0.99858005, 1.        , 1.        ])

u, d, v =  np.linalg.svd(Z, full_matrices=False) # 特異値分解
np.isclose(Z, u @ np.diag(d) @ v).all()          # 元に戻ることの確認
#> True

Z @ v.T # 主成分スコアは先とほぼ同じになる（結果は割愛）

e = d ** 2 / len(my_data) # 分散共分散行列の固有値
e.cumsum() / e.sum()      # 累積寄与率
#> array([0.88848331, 0.97962854, 0.99858005, 1.        , 1.        ])

